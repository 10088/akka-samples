akka {

  projection {
    jdbc {
      dialect = "postgres-dialect"
      offset-store {
        schema = ""
        table = "AKKA_PROJECTION_OFFSET_STORE"
      }
      blocking-jdbc-dispatcher {
        type = Dispatcher
        executor = "thread-pool-executor"
        thread-pool-executor {
          fixed-pool-size = 10
        }
      }
    }
  }

  loglevel = DEBUG

  actor {
    provider = cluster

    serialization-bindings {
      "akka.projection.testing.CborSerializable" = jackson-cbor
    }
  }

  # For the sample, just bind to loopback and do not allow access from the network
  # the port is overridden by the logic in main class
  remote.artery {
    canonical.port = 0
    canonical.hostname = 127.0.0.1
  }

  cluster {
    seed-nodes = [
      "akka://test@127.0.0.1:2551",
      "akka://test@127.0.0.1:2552"
    ]

    roles = ["write-model", "read-model"]

    downing-provider-class = "akka.cluster.sbr.SplitBrainResolverProvider"
  }

  # use Cassandra to store both snapshots and the events of the persistent actors
  persistence {
    journal.plugin = "akka.persistence.cassandra.journal"
    snapshot-store.plugin = "akka.persistence.cassandra.snapshot"
  }

}

# Configuration for akka-persistence-cassandra
akka.persistence.cassandra {
  journal {
    keyspace = "akka_testing"
  }

  events-by-tag {
    bucket-size = "Hour"
    # for reduced latency
    eventual-consistency-delay = 200ms
    flush-interval = 50ms
    pubsub-notification = on
    first-time-bucket = "20201001T00:00"
  }

  query {
    refresh-interval = 2s
  }

  # don't use autocreate in production
  journal.keyspace-autocreate = on
  journal.tables-autocreate = on
  snapshot.keyspace-autocreate = on
  snapshot.tables-autocreate = on
}

datastax-java-driver {
  advanced.reconnect-on-init = on
}

event-processor {
  parallelism = 4
}

test {

}



